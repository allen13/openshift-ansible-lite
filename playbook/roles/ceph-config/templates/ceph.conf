#jinja2: trim_blocks: "true", lstrip_blocks: "true"
[global]
fsid = {{ ceph_fsid }}
public_network = {{ ceph_public_network }}

auth_cluster_required = cephx
auth_service_required = cephx
auth_client_required = cephx

cephx_require_signatures = false # Kernel RBD does NOT support signatures!
cephx_cluster_require_signatures = true
cephx_service_require_signatures = false

max_open_files = 131072
mon_osd_full_ratio = .95
mon_osd_nearfull_ratio = .85
osd_pool_default_min_size = 1
osd_pool_default_pg_num = 8
osd_pool_default_pgp_num = 8
osd_pool_default_size = {{ ceph_osd_pool_default_size }}

[client]
rbd_cache_enabled = true
rbd_cache_writethrough_until_flush = true

[mon]
mon_clock_drift_allowed = .15
mon_clock_drift_warn_backoff = 30
mon_osd_down_out_interval = 600
mon_osd_min_down_reporters = 4
mon_osd_report_timeout = 300
mon_pg_warn_max_per_osd = {{ ceph_mon_pg_warn_max_per_osd }}

{% for host in ceph_dc_mon_group %}
[mon.{{ hostvars[host]['inventory_hostname'] }}]
host = {{ hostvars[host]['inventory_hostname'] }}
mon_addr = {{ hostvars[host]['private_ip'] }}:6789
{% endfor %}

[osd]
filestore_max_sync_interval = 5
filestore_merge_threshold = 40
filestore_op_threads = 8
filestore_split_multiple = 8
journal_size = 100
ms_bind_port_max = 7100
ms_bind_port_min = 6800
osd_client_op_priority = 63
osd_crush_update_on_start = true
osd_max_backfills = 2
osd_max_scrubs = 1
osd_mkfs_options_btrfs = "-f"
osd_mkfs_options_xfs = "-f -i size=2048"
osd_mkfs_type = xfs
osd_mon_heartbeat_interval = 30
osd_objectstore = filestore
osd_op_threads = 8
osd_recovery_max_active = 5
osd_recovery_max_chunk = 1048576
osd_recovery_op_priority = 2
osd_recovery_threads = 1
pool_default_crush_rule = 0

{% if ceph_dc_rgw_group is defined %}
{% for host in ceph_dc_rgw_group %}
[client.rgw.{{ hostvars[host]['inventory_hostname'] }}]
host = {{ hostvars[host]['inventory_hostname'] }}
keyring = {{ ceph_data_location }}/radosgw/{{ ceph_cluster_name }}-rgw.{{ hostvars[host]['inventory_hostname'] }}/keyring
rgw_socket_path = /tmp/radosgw-{{ hostvars[host]['inventory_hostname'] }}.sock
log_file = /var/log/ceph/{{ ceph_cluster_name }}-rgw-{{ hostvars[host]['inventory_hostname'] }}.log
rgw_data = {{ ceph_data_location }}/radosgw/{{ ceph_cluster_name }}-rgw.{{ hostvars[host]['inventory_hostname'] }}
rgw_frontends = civetweb port={{ ceph_radosgw_civetweb_port }}
rgw_num_rados_handles = 8
{% endfor %}
{% endif %}
